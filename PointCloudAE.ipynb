{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import model\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "output_folder = \"output/\" # folder path to save the results\n",
    "save_results = True # save the results to output_folder\n",
    "use_GPU = True # use GPU, False to use CPU\n",
    "latent_size = 128 # bottleneck size of the Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3746, 1024, 3)\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "from Dataloaders import GetDataLoaders\n",
    "\n",
    "pc_array = np.load(\"data/chair_set.npy\")\n",
    "#pc_tensor = torch.load(\"preprocessed_point_cloud.pt\")\n",
    "#pc_tensor = torch.load(\"preprocessed_train_point_cloud.pt\")\n",
    "#pc_array = pc_tensor.numpy()\n",
    "print(pc_array.shape)\n",
    "\n",
    "# load dataset from numpy array and divide 90%-10% randomly for train and test sets\n",
    "train_loader, test_loader = GetDataLoaders(npArray=pc_array, batch_size=batch_size, train_set_percentage=0.9)\n",
    "\n",
    "# Assuming all models have the same size, get the point size from the first model\n",
    "point_size = len(train_loader.dataset[0])\n",
    "print(point_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.PointCloudAE(point_size,latent_size)\n",
    "\n",
    "if(use_GPU):\n",
    "    device = torch.device(\"mps\")\n",
    "    if torch.cuda.device_count() > 1: # if there are multiple GPUs use all\n",
    "        net = torch.nn.DataParallel(net)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch3d.loss import chamfer_distance # chamfer distance for calculating point cloud distance\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def chamfer_distance(x, y, batch_reduction=\"mean\", point_reduction=\"mean\"):\n",
    "    \"\"\"\n",
    "    Compute the chamfer distance between two point clouds x and y\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: torch.Tensor\n",
    "        First point cloud, shape (batch_size, num_points_x, dim)\n",
    "    y: torch.Tensor\n",
    "        Second point cloud, shape (batch_size, num_points_y, dim)\n",
    "    batch_reduction: str\n",
    "        Reduction operation to apply across the batch dimension: 'mean', 'sum' or None\n",
    "    point_reduction: str\n",
    "        Reduction operation to apply across the point dimension: 'mean', 'sum' or None\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dist_chamfer: torch.Tensor\n",
    "        Chamfer distance between the point clouds\n",
    "    \"\"\"\n",
    "    # Check input dimensions\n",
    "    if x.dim() != 3 or y.dim() != 3:\n",
    "        raise ValueError(\"Input point clouds must be 3-dimensional tensors\")\n",
    "    \n",
    "    # Extract batch size and number of points\n",
    "    batch_size, num_points_x, dim = x.shape\n",
    "    _, num_points_y, _ = y.shape\n",
    "    \n",
    "    # Reshape to compute pairwise distances efficiently\n",
    "    x_expanded = x.unsqueeze(2)  # [batch_size, num_points_x, 1, dim]\n",
    "    y_expanded = y.unsqueeze(1)  # [batch_size, 1, num_points_y, dim]\n",
    "    \n",
    "    # Compute squared distances between each pair of points\n",
    "    # |x-y|^2 = |x|^2 + |y|^2 - 2*xÂ·y\n",
    "    dist = ((x_expanded - y_expanded) ** 2).sum(dim=3)  # [batch_size, num_points_x, num_points_y]\n",
    "    \n",
    "    # For each point in x, find the distance to the closest point in y\n",
    "    # Use values, not tuples from min()\n",
    "    x_to_y = torch.min(dist, dim=2).values  # [batch_size, num_points_x]\n",
    "    \n",
    "    # For each point in y, find the distance to the closest point in x\n",
    "    y_to_x = torch.min(dist, dim=1).values  # [batch_size, num_points_y]\n",
    "    \n",
    "    # Apply point reduction\n",
    "    if point_reduction == \"mean\":\n",
    "        x_to_y = x_to_y.mean(dim=1)  # [batch_size]\n",
    "        y_to_x = y_to_x.mean(dim=1)  # [batch_size]\n",
    "    elif point_reduction == \"sum\":\n",
    "        x_to_y = x_to_y.sum(dim=1)  # [batch_size]\n",
    "        y_to_x = y_to_x.sum(dim=1)  # [batch_size]\n",
    "    elif point_reduction is None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid point_reduction: {point_reduction}\")\n",
    "    \n",
    "    # Combine the two directional distances\n",
    "    chamfer_dist = x_to_y + y_to_x  # [batch_size] or [batch_size, num_points]\n",
    "    \n",
    "    # Apply batch reduction\n",
    "    if batch_reduction == \"mean\":\n",
    "        chamfer_dist = chamfer_dist.mean()\n",
    "    elif batch_reduction == \"sum\":\n",
    "        chamfer_dist = chamfer_dist.sum()\n",
    "    elif batch_reduction is None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid batch_reduction: {batch_reduction}\")\n",
    "    \n",
    "    return chamfer_dist\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.to(device)\n",
    "        output = net(data.permute(0,2,1)) # transpose data for NumberxChannelxSize format\n",
    "        loss = chamfer_distance(data, output) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(data): # test with a batch of inputs\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        output = net(data.permute(0,2,1))\n",
    "        loss = chamfer_distance(data, output)\n",
    "        \n",
    "    return loss.item(), output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(): # test with all test set\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        for i, data in enumerate(test_loader):\n",
    "            loss, output = test_batch(data)\n",
    "            epoch_loss += loss\n",
    "\n",
    "    return epoch_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(save_results):\n",
    "    utils.clear_folder(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss_list = []  \n",
    "# test_loss_list = []  \n",
    "\n",
    "# for i in range(1001) :\n",
    "\n",
    "#     startTime = time.time()\n",
    "    \n",
    "#     train_loss = train_epoch() #train one epoch, get the average loss\n",
    "#     train_loss_list.append(train_loss)\n",
    "    \n",
    "#     test_loss = test_epoch() # test with test set\n",
    "#     test_loss_list.append(test_loss)\n",
    "    \n",
    "#     epoch_time = time.time() - startTime\n",
    "    \n",
    "#     writeString = \"epoch \" + str(i) + \" train loss : \" + str(train_loss) + \" test loss : \" + str(test_loss) + \" epoch time : \" + str(epoch_time) + \"\\n\"\n",
    "    \n",
    "#     # plot train/test loss graph\n",
    "#     plt.plot(train_loss_list, label=\"Train\")\n",
    "#     plt.plot(test_loss_list, label=\"Test\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     if(save_results): # save all outputs to the save folder\n",
    "\n",
    "#         # write the text output to file\n",
    "#         with open(output_folder + \"prints.txt\",\"a\") as file: \n",
    "#             file.write(writeString)\n",
    "\n",
    "#         # update the loss graph\n",
    "#         plt.savefig(output_folder + \"loss.png\")\n",
    "#         plt.close()\n",
    "\n",
    "#         # save input/output as image file\n",
    "#         if(i%50==0):\n",
    "#             test_samples = next(iter(test_loader))\n",
    "#             loss , test_output = test_batch(test_samples)\n",
    "#             utils.plot_pointcloud_comparison(test_samples, test_output, show=False, save=True, name = (output_folder  + \"epoch_\" + str(i)))\n",
    "#     else : # display all outputs\n",
    "        \n",
    "#         test_samples = next(iter(test_loader))\n",
    "#         loss , test_output = test_batch(test_samples)\n",
    "#         utils.plotPCbatch(test_samples,test_output)\n",
    "\n",
    "#         print(writeString)\n",
    "\n",
    "#         plt.show()\n",
    "#         timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "#         plt.savefig(f\"model:{timestamp}.png\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 2, 1], expected input[1, 3, 1024] to have 2 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss, _, _ \u001b[38;5;241m=\u001b[39m chamfer_distance(inputs, outputs), inputs, outputs\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/exjobb/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/exjobb/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/exjobb/playground/VGAE/src/pointcloudAE/model.py:45\u001b[0m, in \u001b[0;36mPointCloudAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 45\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     46\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x)\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/exjobb/playground/VGAE/src/pointcloudAE/model.py:31\u001b[0m, in \u001b[0;36mPointCloudAE.encoder\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mencoder\u001b[39m(\u001b[39mself\u001b[39m, x): \n\u001b[0;32m---> 31\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m     32\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m     33\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x))\n",
      "File \u001b[0;32m~/Desktop/exjobb/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/exjobb/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/exjobb/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Desktop/exjobb/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\n\u001b[1;32m    371\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    372\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 2, 1], expected input[1, 3, 1024] to have 2 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    total_train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.permute(0,2,1))\n",
    "        loss, _, _ = chamfer_distance(inputs, outputs), inputs, outputs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs = data.to(device)\n",
    "            outputs = net(inputs.permute(0,2,1))\n",
    "            loss, _, _ = chamfer_distance(inputs, outputs), inputs, outputs\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.6f} - Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "# Plot losses\n",
    "plt.figure()\n",
    "plt.plot(range(1, epochs+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, epochs+1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Chamfer Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "plot_path = os.path.join(output_folder, \"loss_plot.png\")\n",
    "plt.savefig(plot_path)\n",
    "plt.close()\n",
    "print(f\"Loss plot saved to: {plot_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1ed0bf4ef806552ff8112d5f6bf59be565fe8eb3a3e4db7ad4975a55031495b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
